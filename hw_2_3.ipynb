{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['split', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn import datasets, cross_validation, metrics, neighbors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pandas import DataFrame\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    boston['data'], boston['target'], test_size=0.25, random_state=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def H(data):\n",
    "    return np.sum([(data[i] - np.mean(data))**2 for i in range(len(data))]) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def G(data_1, data_2):\n",
    "    l = len(data_1)\n",
    "    r = len(data_2)\n",
    "    q = l + r\n",
    "    return l / q * H(data_1) + r / q * H(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depth(node):\n",
    "    k = 0\n",
    "    while node.parent != 0:\n",
    "        node = node.parent\n",
    "        k += 1\n",
    "    return k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature, step, parent = 0, kid_1 = 0, kid_2 = 0):\n",
    "        self.feature = feature\n",
    "        self.step = step\n",
    "        self.answer = 0\n",
    "        self.parent = parent\n",
    "        self.kid_1 = kid_1\n",
    "        self.kid_2 = kid_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем параметры дерева для лучшего обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_num = 70\n",
    "objects_num = 9\n",
    "depth_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree(self, data, targets, node):\n",
    "    best_feature = 0\n",
    "    best_step = 0\n",
    "    min_G = 1000\n",
    "    \n",
    "    for feature in range(13):\n",
    "        min_value = np.min([data[i][feature] for i in range(len(data))])\n",
    "        max_value = np.max([data[i][feature] for i in range(len(data))])\n",
    "        for step in [min_value + (i + 1)*(max_value - min_value) / steps_num for i in range(steps_num - 1)]:\n",
    "            if G(split(data, targets, feature, step)[2], \n",
    "                 split(data, targets, feature, step)[3]) < min_G:\n",
    "                min_G = G(split(data, targets, feature, step)[2], \n",
    "                        split(data, targets, feature, step)[3])\n",
    "                best_feature = feature\n",
    "                best_step = step\n",
    "                \n",
    "    node.feature = best_feature\n",
    "    node.step = best_step\n",
    "    node.kid_1 = Node(0, 0)\n",
    "    node.kid_2 = Node(0, 0)\n",
    "    node.kid_1.answer = np.mean(split(data, targets, best_feature, best_step)[2])\n",
    "    node.kid_2.answer = np.mean(split(data, targets, best_feature, best_step)[3])\n",
    "    node.kid_1.parent = node\n",
    "    node.kid_2.parent = node\n",
    "    self.nodes.append(node)\n",
    "    if (depth(node) < depth_num and len(split(data, targets, best_feature, best_step)[0]) > objects_num and \n",
    "        len(split(data, targets, best_feature, best_step)[1]) > objects_num):\n",
    "        tree(self, split(data, targets, best_feature, best_step)[0], \n",
    "                     split(data, targets, best_feature, best_step)[2], node.kid_1) \n",
    "        tree(self, split(data, targets, best_feature, best_step)[1], \n",
    "                     split(data, targets, best_feature, best_step)[3], node.kid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split(data, targets, feature, step):\n",
    "    left_feature = []\n",
    "    right_feature = []\n",
    "    left_target = []\n",
    "    right_target = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i][feature] < step:\n",
    "            left_feature.append(data[i])\n",
    "            left_target.append(targets[i])\n",
    "        else:\n",
    "            right_feature.append(data[i])\n",
    "            right_target.append(targets[i])\n",
    "    return (left_feature, right_feature, left_target, right_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "        \n",
    "    def fit(self, X_data, y_data):\n",
    "        self.nodes = []\n",
    "        self.head = Node(0, 0)\n",
    "        tree(self, X_data, y_data, self.head)\n",
    "    \n",
    "    def predict(self, X_data):\n",
    "        res = [0.0 for i in range(len(X_data))]\n",
    "        for i in range(len(X_data)):\n",
    "            node = self.head\n",
    "            while (node.kid_1 != 0 or node.kid_2 != 0):\n",
    "                if (X_data[i][node.feature] < node.step):\n",
    "                    node = node.kid_1\n",
    "                else:\n",
    "                    node = node.kid_2\n",
    "            res[i] = node.answer\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "algo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = algo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MSE for my tree:', 85.617741236482217)\n",
      "('MSE for tests:', 99.058473556947106)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MSE for my tree:\", mean_squared_error(y_test, test))\n",
    "print(\"MSE for tests:\", np.var(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MSE for sklearn.tree:', 17.863667255899156)\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth = 7)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"MSE for sklearn.tree:\", mean_squared_error(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из сравнения понятно, что написанный класс работает почти так же, как sklearn, и лучше, чем просто отвечать средним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
